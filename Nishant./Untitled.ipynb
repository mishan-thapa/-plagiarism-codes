{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d9c210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e15c4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7a7564e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "class tokenize:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def word_tokenize(self,text):\n",
    "        self.text = text\n",
    "        import string\n",
    "        punctuations = list(string.punctuation)\n",
    "        # Add the Nepali purnabiram to the list of punctuations\n",
    "        punctuations.append(\"।\")\n",
    "        punctuations.append(\"”\")\n",
    "        punctuations.append(\"“\")\n",
    "        punctuations.append(\"’\")\n",
    "        punctuations.append(\"‘\")\n",
    "        for punctuation in punctuations:\n",
    "            self.text = self.text.replace(punctuation, ' ')\n",
    "        self.text = self.text.strip().split()\n",
    "        return self.text\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"return the tokenized text removing the punctuations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529674a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowballstemmer\n",
    "\n",
    "class stemming:\n",
    "    def __init__(self):\n",
    "        self.stemmer = snowballstemmer.NepaliStemmer()\n",
    "\n",
    "    def word_stemmer(self, tokens):\n",
    "        if isinstance(tokens, str):\n",
    "            tokens = tokens.split()\n",
    "        stemmed_tokens = [self.stemmer.stemWord(token) for token in tokens]\n",
    "        return stemmed_tokens\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"stemming is done on Nepali words and returns the list of stemmed words.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "396f9e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stopwords:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def stopword_removal(self,tokens):\n",
    "        self.tokens = tokens\n",
    "        f = open('stopwords_ne.txt','r',encoding='utf-8')\n",
    "        stopwords_list = f.read()\n",
    "        new_tokens = list() #new_tokens hold the list of words after removing stopwords\n",
    "        for token in self.tokens:\n",
    "            if token not in stopwords_list:\n",
    "                new_tokens.append(token)\n",
    "\n",
    "        return new_tokens\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"returns the tokens after removing stopwords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf68fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_english_from_nepali(nepali_text):\n",
    "    # Define regular expression to match English words and characters\n",
    "    english_pattern = re.compile(r'[a-zA-Z]+')\n",
    "    \n",
    "    # Remove English words and characters from the Nepali text\n",
    "    nepali_text = re.sub(english_pattern, '', nepali_text)\n",
    "    \n",
    "    # Return the cleaned Nepali text\n",
    "    return nepali_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1dd22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"एक व्यक्ति घोडामा बाहिर छ ।\"\n",
    "text2 = \"घोडामा सवार एकजना भाँचिएको हवाइजहाजमाथि हाम फाल्छन् ।\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c29e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " def preprocess(text):\n",
    "    tokenizer = tokenize()\n",
    "    stemmer=stemming()\n",
    "    stop_removal=stopwords()\n",
    "    tokens = tokenizer.word_tokenize(text)\n",
    "    stemmed_tokens = stemmer.word_stemmer(tokens)\n",
    "    removed_tokens=stop_removal.stopword_removal(stemmed_tokens)\n",
    "    return removed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c6f17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(text,n):\n",
    "    tokens=list(preprocess(text))\n",
    "    grams = list(ngrams(tokens, n))\n",
    "    return grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ffdfe50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_similarity(text1, text2,n):\n",
    "    grams1=n_grams(text1,n)\n",
    "    grams2=n_grams(text2,n)\n",
    "    # Convert the bigrams lists to sets\n",
    "    set1 = set(grams1)\n",
    "    set2 = set(grams2)\n",
    "    A = set(set1)\n",
    "    B = set(set2)\n",
    "    numerator = len(A.intersection(B))\n",
    "    min_len = min(len(A), len(B))\n",
    "    if min_len==0:\n",
    "        jaccard_similarity=0\n",
    "    else:\n",
    "        jaccard_similarity = numerator/min_len\n",
    "    return jaccard_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8b892f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('समकालीन', 'इन्टरनेट'), ('इन्टरनेट', 'संस्कृति'), ('संस्कृति', 'व्यक्ति'), ('व्यक्ति', 'संस्था'), ('संस्था', 'बारम्बार'), ('बारम्बार', 'संख्या'), ('संख्या', 'श्रद्धांजलि'), ('श्रद्धांजलि', 'दिन्'), ('दिन्', 'कम्प्युटर'), ('कम्प्युटर', 'वैज्ञानिक'), ('वैज्ञानिक', 'डोनाल्ड'), ('डोनाल्ड', 'नुथ'), ('नुथ', 'कार्यक्रम'), ('कार्यक्रम', 'संस्करण'), ('संस्करण', 'नम्बर'), ('नम्बर', 'हेर्न'), ('हेर्न', 'संस्करण'), ('संस्करण', '३'), ('३', '३'), ('३', '१'), ('१', '३'), ('३', '१४')]\n",
      "[('समकालीन', 'वेब'), ('वेब', 'संस्कृति'), ('संस्कृति', 'मानिस'), ('मानिस', 'संघ'), ('संघ', 'सकेसम्म'), ('सकेसम्म', 'प्रायः'), ('प्रायः', 'संख्या'), ('संख्या', 'प्रशंसा'), ('प्रशंसा', 'पीसी'), ('पीसी', 'अनुसन्धानकर्ता'), ('अनुसन्धानकर्ता', 'डोनाल्ड'), ('डोनाल्ड', 'नथ'), ('नथ', 'कार्यक्रम'), ('कार्यक्रम', 'दृष्टिकोण'), ('दृष्टिकोण', 'रेन्डिसन'), ('रेन्डिसन', 'मात्रा'), ('मात्रा', 'अनुमति'), ('अनुमति', 'अनुकूलन'), ('अनुकूलन', '३'), ('३', '३'), ('३', '१'), ('१', '३'), ('३', '१४')]\n"
     ]
    }
   ],
   "source": [
    "similarity_score2=overlap_similarity(text1,text2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "01bc29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=\"समकालीन इन्टरनेट संस्कृतिमा, व्यक्ति र संस्थाहरूले बारम्बार संख्यालाई श्रद्धांजलि दिन्छन्। उदाहरणका लागि, कम्प्युटर वैज्ञानिक डोनाल्ड नुथले आफ्नो कार्यक्रम  को संस्करण नम्बरहरू हेर्न दिनुभयो। संस्करणहरू ३, ३.१, ३.१४, र यति अगाडि छन्।\"\n",
    "text2=\"समकालीन वेब संस्कृतिमा, मानिसहरू र संघहरू सकेसम्म प्रायः संख्याको प्रशंसा गर्छन्। उदाहरणका लागि, पीसी अनुसन्धानकर्ता डोनाल्ड नथले आफ्नो कार्यक्रम  दृष्टिकोणको रेन्डिसन मात्रालाई अनुमति दिनुभयो। अनुकूलनहरू ३, ३.१, ३.१४, आदि हुन्।\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b52327c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "print(similarity_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d17a0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=\"दुई गोरा महिला एक अर्कालाई अँगालो हाल्दै छन्।\"\n",
    "text2=\"दुई गोरा महिला एक अर्कालाई अँगालो हाल्दै छन्।\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b86ae",
   "metadata": {},
   "source": [
    "# Longest Common Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "81d88c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(seq, n):\n",
    "    \"\"\"Generate a list of n-grams from a sequence.\"\"\"\n",
    "    return [seq[i:i+n] for i in range(len(seq)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "60004138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_common_sequence(seq1, seq2, max_n):\n",
    "    \"\"\"Find the longest common sequence of words between two sequences using n-grams.\"\"\"\n",
    "    words1 = seq1.split()\n",
    "    words2 = seq2.split()\n",
    "    n = max_n\n",
    "    while n > 0:\n",
    "        ngrams1 = generate_ngrams(words1, n)\n",
    "        ngrams2 = generate_ngrams(words2, n)\n",
    "        m = [[0] * (len(ngrams2)+1) for _ in range(len(ngrams1)+1)]\n",
    "        for i in range(1, len(ngrams1)+1):\n",
    "            for j in range(1, len(ngrams2)+1):\n",
    "                if ngrams1[i-1] == ngrams2[j-1]:\n",
    "                    m[i][j] = m[i-1][j-1] + 1\n",
    "                else:\n",
    "                    m[i][j] = max(m[i-1][j], m[i][j-1])\n",
    "        lcs_length = m[-1][-1]\n",
    "        if lcs_length > 0:\n",
    "            lcs = []\n",
    "            i, j = len(ngrams1), len(ngrams2)\n",
    "            while lcs_length > 0:\n",
    "                if ngrams1[i-1] == ngrams2[j-1]:\n",
    "                    lcs.append(ngrams1[i-1])\n",
    "                    i -= 1\n",
    "                    j -= 1\n",
    "                    lcs_length -= 1\n",
    "                elif m[i-1][j] > m[i][j-1]:\n",
    "                    i -= 1\n",
    "                else:\n",
    "                    j -= 1\n",
    "            lcs.reverse()\n",
    "            lcs_words = [lcs[0]]\n",
    "            for i in range(1, len(lcs)):\n",
    "                overlap = n - 1\n",
    "                while overlap >= 0:\n",
    "                    if lcs[i-1][n-overlap:] == lcs[i][:overlap]:\n",
    "                        break\n",
    "                    overlap -= 1\n",
    "                lcs_words.append(lcs[i][overlap:])\n",
    "            return lcs_words\n",
    "        n -= 1\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5a062ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[['घोडामा']]\n"
     ]
    }
   ],
   "source": [
    "text1=\"एक व्यक्ति घोडामा बाहिर छ।\"\n",
    "text2 = \"घोडामा सवार एकजना भाँचिएको हवाइजहाजमाथि हाम फाल्छन्।\"\n",
    "words = text1.split()\n",
    "n = len(words)\n",
    "print(n)\n",
    "lcs = find_longest_common_sequence(text1, text2,n)\n",
    "print(lcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26940c1",
   "metadata": {},
   "source": [
    "# exporting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3f812ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपोलो ११ अन्तरिक्ष उडान थियो जसले चन्द्रमामा प...</td>\n",
       "      <td>अपोलो ११ चन्द्रमामा प्रारम्भिक दुई व्यक्तिहरूल...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>अपोलो ११ जुलाई १६ मा १३:३२ यूटीसी मा मेरिट आइल...</td>\n",
       "      <td>अपोलो ११ लाई जुलाई १६ मा १३:३२ यूटीसी मा मेरिट...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>शनि V को तेस्रो चरणबाट चन्द्रमामा पठाएपछि, अन्...</td>\n",
       "      <td>शनि V को तेस्रो चरणबाट चन्द्रमामा पठाइएपछि, अन...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>चन्द्रमाको सतहमा आर्मस्ट्रङको पहिलो पाइला विश्...</td>\n",
       "      <td>चन्द्रमाको सतहमा आर्मस्ट्रङको प्रारम्भिक कदमला...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>१९५० को दशकको अन्त र १९६० को प्रारम्भमा, संयुक...</td>\n",
       "      <td>सन् १९५० को दशकको उत्तरार्ध र सन् १९६० को मध्य...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>केनेडी विश्वास गर्थे कि यो संयुक्त राज्यको राष...</td>\n",
       "      <td>केनेडीले विश्वास गरे कि यो संयुक्त राज्यको राष...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>चन्द्रमामा मानिसलाई अवतरण गर्ने प्रयासको पहिले...</td>\n",
       "      <td>चन्द्रमामा मानिस पुग्ने प्रयासको पहिले नाम थिय...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>एपोलोका लागि आवश्यक प्रविधि र प्राविधिकहरू प्र...</td>\n",
       "      <td>एपोलोका लागि आवश्यक आविष्कार र विधिहरू प्रोजेक...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>सोभियत संघले अन्तरिक्ष दौडमा अमेरिकासँग प्रतिस...</td>\n",
       "      <td>सोभियत संघले अन्तरिक्ष दौडमा अमेरिकासँग प्रतिस...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>अपोलो ९ को लागि ब्याकअप क्रुमा कमाण्डर नील आर्...</td>\n",
       "      <td>अपोलो ९ को सुदृढीकरण टोलीमा कमाण्डर नील आर्मस्...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Column 1  \\\n",
       "0  अपोलो ११ अन्तरिक्ष उडान थियो जसले चन्द्रमामा प...   \n",
       "1  अपोलो ११ जुलाई १६ मा १३:३२ यूटीसी मा मेरिट आइल...   \n",
       "2  शनि V को तेस्रो चरणबाट चन्द्रमामा पठाएपछि, अन्...   \n",
       "3  चन्द्रमाको सतहमा आर्मस्ट्रङको पहिलो पाइला विश्...   \n",
       "4  १९५० को दशकको अन्त र १९६० को प्रारम्भमा, संयुक...   \n",
       "5  केनेडी विश्वास गर्थे कि यो संयुक्त राज्यको राष...   \n",
       "6  चन्द्रमामा मानिसलाई अवतरण गर्ने प्रयासको पहिले...   \n",
       "7  एपोलोका लागि आवश्यक प्रविधि र प्राविधिकहरू प्र...   \n",
       "8  सोभियत संघले अन्तरिक्ष दौडमा अमेरिकासँग प्रतिस...   \n",
       "9  अपोलो ९ को लागि ब्याकअप क्रुमा कमाण्डर नील आर्...   \n",
       "\n",
       "                                            Column 2  Column 3  \n",
       "0  अपोलो ११ चन्द्रमामा प्रारम्भिक दुई व्यक्तिहरूल...       NaN  \n",
       "1  अपोलो ११ लाई जुलाई १६ मा १३:३२ यूटीसी मा मेरिट...       NaN  \n",
       "2  शनि V को तेस्रो चरणबाट चन्द्रमामा पठाइएपछि, अन...       NaN  \n",
       "3  चन्द्रमाको सतहमा आर्मस्ट्रङको प्रारम्भिक कदमला...       NaN  \n",
       "4  सन् १९५० को दशकको उत्तरार्ध र सन् १९६० को मध्य...       NaN  \n",
       "5  केनेडीले विश्वास गरे कि यो संयुक्त राज्यको राष...       NaN  \n",
       "6  चन्द्रमामा मानिस पुग्ने प्रयासको पहिले नाम थिय...       NaN  \n",
       "7  एपोलोका लागि आवश्यक आविष्कार र विधिहरू प्रोजेक...       NaN  \n",
       "8  सोभियत संघले अन्तरिक्ष दौडमा अमेरिकासँग प्रतिस...       NaN  \n",
       "9  अपोलो ९ को सुदृढीकरण टोलीमा कमाण्डर नील आर्मस्...       NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "df = pd.read_csv('combined.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aec0402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV file into a dataframe\n",
    "df = pd.read_csv('only_nepali.csv')\n",
    "\n",
    "# Compute similarity scores for each row\n",
    "gram_similarity = []\n",
    "text = [] \n",
    "for i in range(len(df)):\n",
    "    text1 = df['Column 1'][i]\n",
    "    text2 = df['Column 2'][i]\n",
    "    text1 = remove_english_from_nepali(text1)\n",
    "    text2 = remove_english_from_nepali(text2)\n",
    "    similarity_score = overlap_similarity(text1, text2, 2)\n",
    "    gram_similarity.append(similarity_score) \n",
    "\n",
    "#Add similarity scores as a new column to the dataframe\n",
    "df['gram_similarity'] = gram_similarity\n",
    "\n",
    "\n",
    "# Write the updated dataframe to a new CSV file\n",
    "df.to_csv('gram_similarity.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bae7c3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>gram_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपोलो ११ अन्तरिक्ष उडान थियो जसले चन्द्रमामा प...</td>\n",
       "      <td>अपोलो ११ चन्द्रमामा प्रारम्भिक दुई व्यक्तिहरूल...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>अपोलो ११ जुलाई १६ मा १३:३२ यूटीसी मा मेरिट आइल...</td>\n",
       "      <td>अपोलो ११ लाई जुलाई १६ मा १३:३२ यूटीसी मा मेरिट...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>शनि  को तेस्रो चरणबाट चन्द्रमामा पठाएपछि, अन्त...</td>\n",
       "      <td>शनि  को तेस्रो चरणबाट चन्द्रमामा पठाइएपछि, अन्...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>चन्द्रमाको सतहमा आर्मस्ट्रङको पहिलो पाइला विश्...</td>\n",
       "      <td>चन्द्रमाको सतहमा आर्मस्ट्रङको प्रारम्भिक कदमला...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>१९५० को दशकको अन्त र १९६० को प्रारम्भमा, संयुक...</td>\n",
       "      <td>सन् १९५० को दशकको उत्तरार्ध र सन् १९६० को मध्य...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Column 1  \\\n",
       "0  अपोलो ११ अन्तरिक्ष उडान थियो जसले चन्द्रमामा प...   \n",
       "1  अपोलो ११ जुलाई १६ मा १३:३२ यूटीसी मा मेरिट आइल...   \n",
       "2  शनि  को तेस्रो चरणबाट चन्द्रमामा पठाएपछि, अन्त...   \n",
       "3  चन्द्रमाको सतहमा आर्मस्ट्रङको पहिलो पाइला विश्...   \n",
       "4  १९५० को दशकको अन्त र १९६० को प्रारम्भमा, संयुक...   \n",
       "\n",
       "                                            Column 2  Column 3  \\\n",
       "0  अपोलो ११ चन्द्रमामा प्रारम्भिक दुई व्यक्तिहरूल...       NaN   \n",
       "1  अपोलो ११ लाई जुलाई १६ मा १३:३२ यूटीसी मा मेरिट...       NaN   \n",
       "2  शनि  को तेस्रो चरणबाट चन्द्रमामा पठाइएपछि, अन्...       NaN   \n",
       "3  चन्द्रमाको सतहमा आर्मस्ट्रङको प्रारम्भिक कदमला...       NaN   \n",
       "4  सन् १९५० को दशकको उत्तरार्ध र सन् १९६० को मध्य...       NaN   \n",
       "\n",
       "   gram_similarity  \n",
       "0         0.558442  \n",
       "1         0.527273  \n",
       "2         0.380000  \n",
       "3         0.410256  \n",
       "4         0.458716  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df64512e",
   "metadata": {},
   "source": [
    "# remove english letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc3158ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepali_text = \"नमस्कार, Hello यो एक sample text अपोलो हो।\"\n",
    "cleaned_text = remove_english_from_nepali(nepali_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bccc1268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्कार,  यो एक   अपोलो हो।\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "952b9585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['नमस्कार', 'अपोलो']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df12dca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('नमस्कार', 'अपोलो')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('नमस्कार', 'अपोलो')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams(cleaned_text,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62e4cc9",
   "metadata": {},
   "source": [
    "# REmovig english words from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "242bcb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV file into a dataframe\n",
    "df = pd.read_csv('combined.csv')\n",
    "\n",
    "for i in range(len(df)):\n",
    "    text1 = df['Column 1'][i]\n",
    "    text2 = df['Column 2'][i]\n",
    "    text1 = remove_english_from_nepali(text1)\n",
    "    text2 = remove_english_from_nepali(text2)\n",
    "    df.loc[i, 'Column 1'] = text1\n",
    "    df.loc[i, 'Column 2'] = text2\n",
    "\n",
    "# Write the updated dataframe to a new CSV file\n",
    "df.to_csv('only_nepali.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1f7d4b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.10526315789473684\n",
      "2\n",
      "0.10526315789473684\n",
      "3\n",
      "0.043478260869565216\n",
      "4\n",
      "0.041666666666666664\n",
      "5\n",
      "0.08433734939759036\n",
      "6\n",
      "0.05\n",
      "7\n",
      "0.0\n",
      "8\n",
      "0.0\n",
      "9\n",
      "0.06666666666666667\n",
      "10\n",
      "0.06666666666666667\n",
      "11\n",
      "0.06349206349206349\n",
      "12\n",
      "0.04878048780487805\n",
      "13\n",
      "0.01639344262295082\n",
      "14\n",
      "0.0196078431372549\n",
      "15\n",
      "0.018518518518518517\n",
      "16\n",
      "0.08823529411764706\n",
      "17\n",
      "0.0\n",
      "18\n",
      "0.10909090909090909\n",
      "19\n",
      "0.02127659574468085\n",
      "20\n",
      "0.0\n",
      "21\n",
      "0.20588235294117646\n",
      "22\n",
      "0.0\n",
      "23\n",
      "0.027777777777777776\n",
      "24\n",
      "0.0\n",
      "25\n",
      "0.22857142857142856\n",
      "26\n",
      "0.0\n",
      "27\n",
      "0.1724137931034483\n",
      "28\n",
      "0.1\n",
      "29\n",
      "0.020833333333333332\n",
      "30\n",
      "0.03508771929824561\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV file into a dataframe\n",
    "df = pd.read_csv('test.csv')\n",
    "# Compute similarity scores for each row\n",
    "gram_similarity = []\n",
    "text = [] \n",
    "j=0\n",
    "for i in range(len(df)):\n",
    "    j=j+1\n",
    "    print(j)\n",
    "    text1 = df['Suspicious'][i]\n",
    "    text2 = df['Original'][i]\n",
    "    #text1 = remove_english_from_nepali(text1)\n",
    "    #text2 = remove_english_from_nepali(text2)\n",
    "    similarity_score = overlap_similarity(text1, text2, 2)\n",
    "    gram_similarity.append(similarity_score) \n",
    "    print(similarity_score)\n",
    "#Add similarity scores as a new column to the dataframe\n",
    "df['gram_similarity'] = gram_similarity\n",
    "\n",
    "\n",
    "# Write the updated dataframe to a new CSV file\n",
    "df.to_csv('gram_similarity.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1561ccd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1197"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nonplagsame.csv')\n",
    "\n",
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d897c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        import string\n",
    "        punctuations = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "998ab38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf0849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
