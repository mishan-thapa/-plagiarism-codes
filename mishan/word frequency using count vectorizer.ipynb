{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3eb268",
   "metadata": {},
   "source": [
    "# Tokenizing, Word Freuency count, TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4ff259",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"i use my pen to write my book\"\n",
    "doc2 = \"i use my spectacles to read my book\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cce883",
   "metadata": {},
   "source": [
    "## Tokenizing \n",
    "using bag of words(BOW) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629785f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'use', 'my', 'pen', 'to', 'write', 'my', 'book']\n",
      "['i', 'use', 'my', 'spectacles', 'to', 'read', 'my', 'book']\n"
     ]
    }
   ],
   "source": [
    "bag1 = doc1.split(\" \")\n",
    "bag2 = doc2.split(\" \")\n",
    "\n",
    "print(bag1)\n",
    "print(bag2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43459f2",
   "metadata": {},
   "source": [
    "# countvectorizer  for word frequency in diff. array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16829b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the library\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16623bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docA = [\"i use my pen to write my book\"]\n",
    "docB = [\"i use my spectacles to read my book\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6815fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer()\n",
    "vectorizer2 = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9c536",
   "metadata": {},
   "source": [
    "# sorts them in alphabetic order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63cacbe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t1\n",
      "  (0, 1)\t2\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 0)\t1\n",
      "gap\n",
      "  (0, 5)\t1\n",
      "  (0, 1)\t2\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "dict1 = vectorizer1.fit_transform(docA)\n",
    "dict2 = vectorizer2.fit_transform(docB)\n",
    "print(dict1)\n",
    "print(\"gap\")\n",
    "print(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f87f1bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1 1 1 1]]\n",
      "[[1 2 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(dict1.todense())\n",
    "print(dict1.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e51b720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'my', 'pen', 'to', 'use', 'write']\n",
      "[[1 2 1 1 1 1]]\n",
      "['book', 'my', 'read', 'spectacles', 'to', 'use']\n",
      "[[1 2 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer1.get_feature_names())\n",
    "print(dict1.todense())\n",
    "print(vectorizer2.get_feature_names())\n",
    "print(dict1.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110181a",
   "metadata": {},
   "source": [
    "# countvectorizer  for word frequency in same array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c0c391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the library\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "804bfe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"i use my pen to write my book\",\"i use my spectacles to read my book\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f42c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76675902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t1\n",
      "  (0, 1)\t2\n",
      "  (0, 2)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 0)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 3)\t1\n"
     ]
    }
   ],
   "source": [
    "dictionary = vectorizer.fit_transform(docs)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28a52f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'my', 'pen', 'read', 'spectacles', 'to', 'use', 'write']\n",
      "[[1 2 1 0 0 1 1 1]\n",
      " [1 2 0 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())\n",
    "print(dictionary.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6207e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
